{"docstore/metadata": {"8efe9c00-8b8f-494f-8001-7d2b0f196d76": {"doc_hash": "3ae36362c91c0f9db0791e0455cce65257ca92337be27ecb8567e026edb63c6d"}, "22718678-3e28-400d-9418-220c360fad00": {"doc_hash": "08bd2d56c0c6ea0c3cfde97b020785f44ed8865dfc96c515750a35c55cab6982"}, "749f5428-30d4-4736-824a-828073a4dbf4": {"doc_hash": "3ae36362c91c0f9db0791e0455cce65257ca92337be27ecb8567e026edb63c6d"}, "70a553c0-9aa1-475a-83d6-460dd00c5efb": {"doc_hash": "08bd2d56c0c6ea0c3cfde97b020785f44ed8865dfc96c515750a35c55cab6982"}}, "docstore/data": {"749f5428-30d4-4736-824a-828073a4dbf4": {"__data__": {"text": "The EU AI Act: A Certification Schema for\nTechnical Robustness, Transparency, and Fairness\nChiara Galimberti\u2217Marco Repetto\u2020\nSeptember 11, 2023\nAbstract\nThis paper discusses the EU AI Act and its role in establishing a certifi-\ncation schema for three key dimensions of artificial intelligence: technical\nrobustness, transparency, and fairness. We analyze the implications of\nthis act on the development and deployment of AI systems within the\nEuropean Union.\n1 Introduction\nThe field of artificial intelligence (AI) has witnessed significant advancements in\nrecent years. However, concerns have been raised regarding the ethical and legal\nimplications of AI systems, particularly in relation to their technical robustness,\ntransparency, and fairness. In response to these concerns, the European Union\n(EU) has introduced the AI Act, which aims to provide a certification schema\nfor addressing these dimensions.\n2 Technical Robustness\nTechnical robustness refers to the ability of an AI system to withstand and adapt\nto unforeseen circumstances. The EU AI Act establishes guidelines and require-\nments for ensuring that AI systems are designed and developed with robustness\nin mind. This section explores the various aspects of technical robustness out-\nlined in the act.\n3 Transparency\nTransparency in AI systems is crucial for building trust and accountability. The\nEU AI Act mandates transparency requirements to ensure that AI systems and\ntheir decision-making processes are explainable and understandable. We delve\ninto the transparency provisions of the act and discuss their implications. [1]\n\u2217TBD\n\u2020CertX, Fribourg, Switzerland.\n1", "doc_id": "749f5428-30d4-4736-824a-828073a4dbf4", "embedding": null, "doc_hash": "3ae36362c91c0f9db0791e0455cce65257ca92337be27ecb8567e026edb63c6d", "extra_info": {"page_label": "1"}, "node_info": {"start": 0, "end": 1636}, "relationships": {"1": "8efe9c00-8b8f-494f-8001-7d2b0f196d76"}}, "__type__": "1"}, "70a553c0-9aa1-475a-83d6-460dd00c5efb": {"__data__": {"text": "4 Fairness\nFairness is a fundamental aspect of AI systems, as they can significantly impact\nvarious aspects of society. The EU AI Act addresses fairness concerns by es-\ntablishing guidelines and requirements for preventing discriminatory and biased\noutcomes. In this section, we analyze the fairness dimension of the act.\n5 Conclusion\nThe EU AI Act plays a pivotal role in providing a certification schema for\nthree relevant dimensions of AI systems: technical robustness, transparency,\nand fairness. By adhering to the requirements outlined in the act, AI developers\nand deployers can ensure the responsible and ethical use of AI technology within\nthe European Union.\nReferences\n[1] Alejandro Barredo Arrieta, Natalia D\u00b4 \u0131az-Rodr\u00b4 \u0131guez, Javier Del Ser, Adrien\nBennetot, Siham Tabik, Alberto Barbado, Salvador Garcia, Sergio Gil-\nLopez, Daniel Molina, Richard Benjamins, Raja Chatila, and Francisco\nHerrera. Explainable Artificial Intelligence (XAI): Concepts, taxonomies,\nopportunities and challenges toward responsible AI. 58:82\u2013115.\n2", "doc_id": "70a553c0-9aa1-475a-83d6-460dd00c5efb", "embedding": null, "doc_hash": "08bd2d56c0c6ea0c3cfde97b020785f44ed8865dfc96c515750a35c55cab6982", "extra_info": {"page_label": "2"}, "node_info": {"start": 0, "end": 1038}, "relationships": {"1": "22718678-3e28-400d-9418-220c360fad00"}}, "__type__": "1"}}}